{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"PO_FolBm2qLs","colab_type":"code","outputId":"fd25766c-dfcf-4443-fe35-b225ba196282","executionInfo":{"status":"ok","timestamp":1551965223452,"user_tz":0,"elapsed":2328,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir('/content/gdrive/My Drive/MA')\n","print(os.listdir(os.getcwd()))\n","import json\n","import pandas as pd\n","import gzip\n","import numpy as np\n","import sys\n","import matplotlib.pyplot as plt\n","import time\n","from __future__ import absolute_import, division, print_function\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.keras.utils import Sequence\n","from sklearn.metrics import log_loss, roc_auc_score, confusion_matrix"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","['SIG Proceedings Template-Jan2015 Zip', '.DS_Store', 'we_data.zip', 'sig-proceedings-template-may2015-zip.zip', 'data', 'click_predictions', 'bid_predictions', 'payprice_predictions', 'Click Prediction Grid Search.gsheet', 'Payprice_Prediction.ipynb', 'Click_Prediction.ipynb', 'data2', 'League_of_Agents.ipynb', 'MA_Feature_Engineering.ipynb', 'Data_Preprocessing.ipynb']\n"],"name":"stdout"}]},{"metadata":{"id":"DgH11jjYP4bj","colab_type":"code","outputId":"e27d5af0-1784-41d5-8e07-a85fbd108370","executionInfo":{"status":"ok","timestamp":1551908754349,"user_tz":0,"elapsed":1041030,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":2601}},"cell_type":"code","source":["folder='data/'\n","for file in ['validation','test','train']:\n","  data=pd.read_csv(folder+file+'.csv')\n","  print(file+' is successfully loaded')\n","  print('No. of rows: ',len(data))\n","\n","  data=data.drop(columns=['bidid','userid','IP','urlid','keypage'])\n","  print('columns \"bidid\", \"userid\", \"IP\", \"urlid\" and \"keypage\" are dropped')\n","  try:\n","    data=data.drop(columns=['bidprice'])\n","    print('column \"bidprice\" is dropped')\n","  except:\n","    pass\n","\n","  for i in range(len(data)):\n","    if not isinstance(data.at[i,'domain'],str):\n","      if isinstance(data.at[i,'url'],str):\n","        data.at[i,'domain']=data.at[i,'url']\n","      else:\n","        data.at[i,'domain']='Na'\n","    if i%200000==0:\n","          print(int(i/100000),'/',int(len(data)/100000))\n","  print('column \"url\" is pasted into column \"domain\" where \"domain\" is nan')\n","  print('nan is reformated as string \"Na\" in column \"domain\"')\n","  data=data.drop(columns='url')\n","  print('column \"url\" is dropped')\n","\n","  for i in range(len(data)):\n","    if np.isnan(data.at[i,'adexchange']):\n","      data.at[i,'adexchange']=-1\n","    if i%200000==0:\n","      print(int(i/100000),'/',int(len(data)/100000))\n","  data['adexchange']=data['adexchange'].astype(int)\n","  print('column \"adexchange\" is reformated from float to int')\n","\n","  data['useros']=''\n","  data['userbrowser']=''\n","  for i in range(len(data)):\n","    user_agent=data.at[i,'useragent'].split('_')\n","    data.at[i,'useros']=user_agent[0]\n","    data.at[i,'userbrowser']=user_agent[1]\n","    if i%200000==0:\n","      print(int(i/100000),'/',int(len(data)/100000))\n","  print('column \"useragent\" is divided into columns \"useros\" and \"userbrowser\"')\n","  data=data.drop(columns='useragent')\n","  print('column \"useragent\" is dropped')\n","\n","  data['slotsize']=''\n","  for i in range(len(data)):\n","    data.at[i,'slotsize']=str(data.at[i,'slotwidth'])+'*'+str(data.at[i,'slotheight'])\n","    if i%200000==0:\n","      print(int(i/100000),'/',int(len(data)/100000))\n","  print('columns \"slotwidth\" and \"slotheight\" are combined into column \"slotsize\"')\n","  data=data.drop(columns=['slotwidth','slotheight'])\n","  print('columns \"slotwidth\" and \"slotheight\" are dropped')\n","\n","  data['slotid0']='Na'\n","  data['slotid1']='Na'\n","  data['slotid2']='Na'\n","  for i in range(len(data)):\n","    slotid=str(data.at[i,'slotid'])\n","    if slotid[0]=='_':\n","      slotid=slotid[1:]\n","    if '_' in slotid:\n","      slotid=slotid.split('_',1)\n","      data.at[i,'slotid0']=slotid[0]\n","      data.at[i,'slotid1']=slotid[1]\n","    elif len(slotid)==1:\n","      data.at[i,'slotid0']=slotid\n","    else:\n","      data.at[i,'slotid2']=slotid\n","    if i%200000==0:\n","      print(int(i/100000),'/',int(len(data)/100000))\n","  print('column \"slotid\" is divided into columns \"slotid0\", \"slotid1\" and \"slotid2\"')\n","  data=data.drop(columns='slotid')\n","  print('column \"slotid\" is dropped')\n","\n","\n","  usertag_set=sorted(list(set(','.join([n for n in data.usertag if isinstance(n,str)]).split(','))))\n","  for tag in usertag_set:\n","    data['usertag_'+tag]=False\n","  for i in range(len(data)):\n","    if isinstance(data.at[i,'usertag'],str):\n","      for tag in data.at[i,'usertag'].split(','):\n","        data.at[i,'usertag_'+tag]=True\n","    if i%200000==0:\n","      print(int(i/100000),'/',int(len(data)/100000))\n","  print('column \"usertag\" is divided into ',len(usertag_set),' binary columns')\n","  data=data.drop(columns='usertag')\n","  print('column \"usertag\" is dropped')\n","  \n","  if file=='validation':\n","    for i in range(len(data)):\n","      if data.at[i,'slotprice']==288:\n","        data.at[i,'slotprice']=287\n","\n","  with open(folder+file+'1.csv','w') as f:\n","    f.write(data.to_csv(index=False))\n","    print('new copy of '+file+' is saved')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["validation is successfully loaded\n","No. of rows:  303925\n","columns \"bidid\", \"userid\", \"IP\", \"urlid\" and \"keypage\" are dropped\n","column \"bidprice\" is dropped\n","0 / 3\n","2 / 3\n","column \"url\" is pasted into column \"domain\" where \"domain\" is nan\n","nan is reformated as string \"Na\" in column \"domain\"\n","column \"url\" is dropped\n","0 / 3\n","2 / 3\n","column \"adexchange\" is reformated from float to int\n","0 / 3\n","2 / 3\n","column \"useragent\" is divided into columns \"useros\" and \"userbrowser\"\n","column \"useragent\" is dropped\n","0 / 3\n","2 / 3\n","columns \"slotwidth\" and \"slotheight\" are combined into column \"slotsize\"\n","columns \"slotwidth\" and \"slotheight\" are dropped\n","0 / 3\n","2 / 3\n","column \"slotid\" is divided into columns \"slotid0\", \"slotid1\" and \"slotid2\"\n","column \"slotid\" is dropped\n","0 / 3\n","2 / 3\n","column \"usertag\" is divided into  68  binary columns\n","column \"usertag\" is dropped\n","new copy of validation is saved\n","test is successfully loaded\n","No. of rows:  303375\n","columns \"bidid\", \"userid\", \"IP\", \"urlid\" and \"keypage\" are dropped\n","0 / 3\n","2 / 3\n","column \"url\" is pasted into column \"domain\" where \"domain\" is nan\n","nan is reformated as string \"Na\" in column \"domain\"\n","column \"url\" is dropped\n","0 / 3\n","2 / 3\n","column \"adexchange\" is reformated from float to int\n","0 / 3\n","2 / 3\n","column \"useragent\" is divided into columns \"useros\" and \"userbrowser\"\n","column \"useragent\" is dropped\n","0 / 3\n","2 / 3\n","columns \"slotwidth\" and \"slotheight\" are combined into column \"slotsize\"\n","columns \"slotwidth\" and \"slotheight\" are dropped\n","0 / 3\n","2 / 3\n","column \"slotid\" is divided into columns \"slotid0\", \"slotid1\" and \"slotid2\"\n","column \"slotid\" is dropped\n","0 / 3\n","2 / 3\n","column \"usertag\" is divided into  68  binary columns\n","column \"usertag\" is dropped\n","new copy of test is saved\n","train is successfully loaded\n","No. of rows:  2430981\n","columns \"bidid\", \"userid\", \"IP\", \"urlid\" and \"keypage\" are dropped\n","column \"bidprice\" is dropped\n","0 / 24\n","2 / 24\n","4 / 24\n","6 / 24\n","8 / 24\n","10 / 24\n","12 / 24\n","14 / 24\n","16 / 24\n","18 / 24\n","20 / 24\n","22 / 24\n","24 / 24\n","column \"url\" is pasted into column \"domain\" where \"domain\" is nan\n","nan is reformated as string \"Na\" in column \"domain\"\n","column \"url\" is dropped\n","0 / 24\n","2 / 24\n","4 / 24\n","6 / 24\n","8 / 24\n","10 / 24\n","12 / 24\n","14 / 24\n","16 / 24\n","18 / 24\n","20 / 24\n","22 / 24\n","24 / 24\n","column \"adexchange\" is reformated from float to int\n","0 / 24\n","2 / 24\n","4 / 24\n","6 / 24\n","8 / 24\n","10 / 24\n","12 / 24\n","14 / 24\n","16 / 24\n","18 / 24\n","20 / 24\n","22 / 24\n","24 / 24\n","column \"useragent\" is divided into columns \"useros\" and \"userbrowser\"\n","column \"useragent\" is dropped\n","0 / 24\n","2 / 24\n","4 / 24\n","6 / 24\n","8 / 24\n","10 / 24\n","12 / 24\n","14 / 24\n","16 / 24\n","18 / 24\n","20 / 24\n","22 / 24\n","24 / 24\n","columns \"slotwidth\" and \"slotheight\" are combined into column \"slotsize\"\n","columns \"slotwidth\" and \"slotheight\" are dropped\n","0 / 24\n","2 / 24\n","4 / 24\n","6 / 24\n","8 / 24\n","10 / 24\n","12 / 24\n","14 / 24\n","16 / 24\n","18 / 24\n","20 / 24\n","22 / 24\n","24 / 24\n","column \"slotid\" is divided into columns \"slotid0\", \"slotid1\" and \"slotid2\"\n","column \"slotid\" is dropped\n","0 / 24\n","2 / 24\n","4 / 24\n","6 / 24\n","8 / 24\n","10 / 24\n","12 / 24\n","14 / 24\n","16 / 24\n","18 / 24\n","20 / 24\n","22 / 24\n","24 / 24\n","column \"usertag\" is divided into  68  binary columns\n","column \"usertag\" is dropped\n","new copy of train is saved\n"],"name":"stdout"}]},{"metadata":{"id":"c-dTRBnlLgNr","colab_type":"code","outputId":"9dfb283e-1430-44b5-bc88-29e879b3115d","executionInfo":{"status":"ok","timestamp":1551894750899,"user_tz":0,"elapsed":137994,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["folder='data/'\n","train1=pd.read_csv(folder+'train1'+'.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str})\n","print('train1'+' is successfully loaded','No. of rows: ',len(train1))\n","#########################\n","for ds_rate in [0.01]:\n","#########################\n","  folder='data/'\n","  data=train1\n","  drop_list=[]\n","  for i in range(len(data)):\n","    if data.at[i,'click']==1:\n","      drop_list.append(i)\n","  positive_data=data.iloc[drop_list]\n","  negative_data=data.drop(drop_list)\n","  positive_data.index=range(len(positive_data))\n","  negative_data.index=range(len(negative_data))\n","  negative_data=negative_data.iloc[np.random.choice(len(negative_data),int(len(negative_data)*ds_rate),replace=False)]\n","  negative_data.index=range(len(negative_data))\n","  data=positive_data.append(negative_data)\n","  data.index=range(len(data))\n","  data=data.iloc[np.random.permutation(len(data))]\n","  data.index=range(len(data))\n","  print('data negative-downsampled',len(data))\n","  \n","  data=data.drop(columns=['domain','slotid1','slotid2'])\n","\n","#   threshold=1\n","#   for column in ['domain','slotid2']:\n","#     print('column \"'+column+'\" has',len(list(set(data[column]))),'unique instances')\n","#     data=data.sort_values(by=column)\n","#     data.index=range(len(data)) \n","#     i=0\n","#     i_start=i\n","#     while i<len(data):\n","#       i+=1\n","#       if i==len(data) or not data.at[i,column]==data.at[i_start,column]:\n","#         if i-i_start<=threshold:\n","#           if data.at[i_start,'click']==0:\n","#             for j in range(i_start,i):\n","#               data.at[j,column]='Na'\n","#         i_start=i\n","#     print('instances with frequency <= '+str(threshold)+' are changed to \"Na\" in column \"'+column+'\"')\n","#     print('column \"'+column+'\" has',len(list(set(data[column]))),'unique instances')\n","\n","#   dic1=dict.fromkeys(sorted(list(set(data['domain']))))\n","#   dic2=dict.fromkeys(sorted(list(set(data['slotid2']))))\n","#   i=0\n","#   for key in dic1.keys():\n","#     dic1[key]=i\n","#     i+=1\n","#   j=0\n","#   for key in dic2.keys():\n","#     dic2[key]=j\n","#     j+=1\n","#   co=np.zeros([i,j]).astype(bool)\n","#   for k in range(len(data)):\n","#     co[dic1[data.at[k,'domain']],dic2[data.at[k,'slotid2']]]=1\n","#   duplicate_list=np.nonzero((np.outer(np.sum(co,axis=1),np.sum(co,axis=0))*co)==1)[1]\n","#   print(len(duplicate_list),'duplicate instances found between column \"domain\" and column \"slotid2\"')\n","#   drop_list=[]\n","#   for key in dic2.keys():\n","#     if dic2[key] in duplicate_list:\n","#       drop_list.append(key)\n","#   for key in drop_list:\n","#     del dic2[key]\n","#   for i in range(len(data)):\n","#     try:\n","#       dummy=dic2[data.at[i,'slotid2']]\n","#     except:\n","#       data.at[i,'slotid2']='Na'\n","#   print('duplicate instances in column \"slotid2\" are changed to \"Na\"')\n","#   print('column \"slotid2\" has',len(list(set(data.slotid2))),'unique instances')\n","\n","  dic={}\n","  for column in data.columns:\n","    if not ('usertag' in column or 'click' in column or 'payprice' in column):\n","      for item in sorted(list(set(data[column]))):\n","        if not (item==-1 or item=='Na'):\n","#           if column in ['domain','slotid1','slotid2']:\n","#             dic[column+'_'+str(item)]=False\n","#           else:\n","            dic[column+'_'+str(item)]=True\n","    elif 'usertag' in column:\n","      dic[column]=True\n","  print('Total unique feature instances:',len(dic.keys()))\n","\n","  datasets={}\n","  datasets['train']=data\n","  datasets['validation']=pd.read_csv(folder+'validation'+'1.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str})\n","  datasets['test']=pd.read_csv(folder+'test'+'1.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str})\n","  \n","  #################################\n","  folder=folder+'minimalfeatures/'\n","  #################################\n","  \n","#   for dataset in ['validation','test']:\n","#     data=datasets[dataset]\n","#     print(dataset,'No. of rows: ',len(data))\n","#     for column in ['domain','slotid1','slotid2']:\n","#       for i in range(len(data)):\n","#         try:\n","#           dummy=dic[column+'_'+str(data.at[i,column])]\n","#           dic[column+'_'+str(data.at[i,column])]=True\n","#         except:\n","#           data.at[i,column]='Na'    \n","#       print('instances which do not appear in training set are changed to \"Na\" in column \"'+column+'\"')\n","  \n","#   drop_list=[]\n","#   for key in dic.keys():\n","#     if dic[key]==False:\n","#       drop_list.append(key)\n","#   for key in drop_list:\n","#     del dic[key]\n","#   print('drop list',len(drop_list))\n","#   print('Total unique feature instances:',len(dic.keys()))\n","  i=0\n","  for key in dic.keys():\n","    dic[key]=i\n","    i+=1\n","  with open(folder+str(ds_rate)+'/'+'dic_'+str(ds_rate)+'.json', 'w') as f:\n","    json.dump(dic, f)\n","\n","  batch_size=int(72000/len(dic.keys()))*10000\n","  print('batch size',batch_size)\n","  category_columns=[column for column in datasets['train'].columns if not ('usertag' in column or 'click' in column or 'payprice' in column)]\n","  binary_columns=[column for column in datasets['train'].columns if 'usertag' in column]\n","  n_category_columns=len(category_columns)\n","  n_binary_category_columns=dic[binary_columns[0]]\n","\n","  for dataset in ['train','validation','test']:\n","    print(dataset)\n","    data=datasets[dataset]\n","    try:\n","      data=data.drop(columns=['domain','slotid1','slotid2'])\n","    except:\n","      pass\n","    \n","    if not dataset=='test':\n","      click=np.asarray(data.click).astype(bool)\n","      payprice=np.asarray(data.payprice).astype(int)\n","      data=data.drop(columns=['click','payprice'])\n","      click.tofile(folder+str(ds_rate)+'/'+'_'.join([dataset,str(ds_rate),'click'])+'.bin')\n","      payprice.tofile(folder+str(ds_rate)+'/'+'_'.join([dataset,str(ds_rate),'payprice'])+'.bin')\n","      print('click and payprice saved')\n","    data=np.asarray(data)\n","    for i in range(int(np.ceil(len(data)/float(batch_size)))):\n","      x=data[i*batch_size:min((i+1)*batch_size,len(data))]\n","      binary_x=np.zeros([len(x),n_binary_category_columns]).astype(bool)\n","      for j in range(len(x)):\n","        for k in range(n_category_columns):\n","          try:\n","            binary_x[j,dic[category_columns[k]+'_'+str(x[j,k])]]=True\n","          except:\n","            pass\n","      binary_x=np.hstack((binary_x,x[:,n_category_columns:])).astype(bool)\n","      binary_x.tofile(folder+str(ds_rate)+'/'+'_'.join([dataset,str(ds_rate),'x',str(i),str(len(x))])+'.bin')\n","      print(i,'x')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train1 is successfully loaded No. of rows:  2430981\n","data negative-downsampled 26084\n","Total unique feature instances: 886\n","batch size 810000\n","train\n","click and payprice saved\n","0 x\n","validation\n","click and payprice saved\n","0 x\n","test\n","0 x\n"],"name":"stdout"}]},{"metadata":{"id":"64Zw3OsDZQu1","colab_type":"code","outputId":"2017bfd5-55bf-4c9d-b1b3-49b5f63c5b26","executionInfo":{"status":"ok","timestamp":1551782304313,"user_tz":0,"elapsed":17968,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["folder='data/'\n","data=pd.read_csv(folder+'validation1'+'.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str})\n","print('No. of rows: ',len(data))\n","drop_list=[]\n","for i in range(len(data)):\n","  if data.at[i,'click']==1:\n","    drop_list.append(i)\n","positive_data=data.iloc[drop_list]\n","positive_data.index=range(len(positive_data))\n","with open(folder+'validation1'+'_positive'+'.csv','w') as f:\n","  f.write(positive_data.to_csv(index=False))\n","print(len(positive_data))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["No. of rows:  303925\n","202\n"],"name":"stdout"}]},{"metadata":{"id":"iv5-tL9GQKyr","colab_type":"code","outputId":"0861e9b9-cce4-4f9c-ea9a-20ed38192854","executionInfo":{"status":"ok","timestamp":1551833892981,"user_tz":0,"elapsed":54572,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"cell_type":"code","source":["payprice_bin_width=10\n","slotprice_bin_width=10\n","folder='data/'\n","data=pd.read_csv(folder+'train1_positive'+'.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str})\n","data.slotprice=np.ceil(np.minimum(data.slotprice,210)/slotprice_bin_width).astype(int)\n","for column in ['domain','slotid2']:\n","  print('column \"'+column+'\" has',len(list(set(data[column]))),'unique instances')\n","  \n","data=data.drop(columns=[])\n","  \n","dic={}\n","for column in data.columns:\n","  if not ('usertag' in column or 'click' in column or 'payprice' in column):\n","    for item in sorted(list(set(data[column]))):\n","      if not (item==-1 or item=='Na'):\n","#         if column in ['domain','slotid1','slotid2']:\n","#           dic[column+'_'+str(item)]=False\n","#         else:\n","          dic[column+'_'+str(item)]=True\n","  elif 'usertag' in column:\n","    dic[column]=True\n","print('Total unique feature instances:',len(dic.keys()))\n","\n","datasets={}\n","datasets['train']=data\n","datasets['validation']=pd.read_csv(folder+'validation'+'1.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str}).drop(columns=[])\n","datasets['test']=pd.read_csv(folder+'test'+'1.csv',dtype={'slotvisibility':str,'slotformat':str,'creative':str,'slotid2':str})\n","\n","i=0\n","for key in dic.keys():\n","  dic[key]=i\n","  i+=1\n","with open(folder+'positive'+'/'+'dic_'+'positive'+'.json', 'w') as f:\n","  json.dump(dic, f)\n","\n","batch_size=int(72000/len(dic.keys()))*10000\n","print('batch size',batch_size)\n","category_columns=[column for column in datasets['train'].columns if not ('usertag' in column or 'click' in column or 'payprice' in column)]\n","binary_columns=[column for column in datasets['train'].columns if 'usertag' in column]\n","n_category_columns=len(category_columns)\n","n_binary_category_columns=dic[binary_columns[0]]\n","\n","for dataset in ['validation','test']:\n","  data=datasets[dataset]\n","  print(dataset,len(data))\n","  if not dataset=='train':\n","    data.slotprice=np.ceil(np.minimum(data.slotprice,210)/slotprice_bin_width).astype(int)\n","  if not dataset=='test':\n","    click=np.asarray(data.click).astype(bool)\n","    data.payprice=np.ceil(np.minimum(data.payprice,300)/payprice_bin_width).astype(int)\n","    payprice=np.zeros([len(data),int(300/payprice_bin_width)+1]).astype(bool)\n","    payprice[range(len(payprice)),data.payprice]=True\n","    data=data.drop(columns=['click','payprice'])\n","    click.tofile(folder+'positive'+'/'+'_'.join([dataset,'original','click'])+'.bin')\n","    payprice.tofile(folder+'positive'+'/'+'_'.join([dataset,'original','payprice',str(payprice.shape[1])])+'.bin')\n","    print('click and payprice saved')\n","  data=np.asarray(data)\n","  for i in range(int(np.ceil(len(data)/float(batch_size)))):\n","    x=data[i*batch_size:min((i+1)*batch_size,len(data))]\n","    binary_x=np.zeros([len(x),n_binary_category_columns]).astype(bool)\n","    for j in range(len(x)):\n","      for k in range(n_category_columns):\n","        try:\n","          binary_x[j,dic[category_columns[k]+'_'+str(x[j,k])]]=True\n","        except:\n","          pass\n","    binary_x=np.hstack((binary_x,x[:,n_category_columns:])).astype(bool)\n","    binary_x.tofile(folder+'positive'+'/'+'_'.join([dataset,'original','x',str(i),str(len(x))])+'.bin')\n","    print(i,'x')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["column \"domain\" has 476 unique instances\n","column \"slotid2\" has 327 unique instances\n","Total unique feature instances: 1660\n","batch size 430000\n","validation 303925\n","click and payprice saved\n","0 x\n","test 303375\n","0 x\n"],"name":"stdout"}]},{"metadata":{"id":"jSiPHBX6VX9V","colab_type":"code","colab":{}},"cell_type":"code","source":["data=pd.read_csv('data2/train1.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U4_HbH2uVglh","colab_type":"code","outputId":"c23c0ff8-88cf-4ede-d423-3225fc7d5f12","executionInfo":{"status":"ok","timestamp":1551965381173,"user_tz":0,"elapsed":507,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["np.count_nonzero(data.usertag_10048==0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2288146"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"KeCSMrr2VsMx","colab_type":"code","outputId":"d329f901-fd91-4ef5-f235-c065332d7cd1","executionInfo":{"status":"ok","timestamp":1551965398218,"user_tz":0,"elapsed":550,"user":{"displayName":"Wen Yang","photoUrl":"","userId":"06774353832900075186"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["np.count_nonzero(data.usertag_10052==0)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2094156"]},"metadata":{"tags":[]},"execution_count":11}]}]}